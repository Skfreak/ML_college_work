{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDf = pd.read_csv('../datasets/Data_Q2/iris.csv')\n",
    "\n",
    "irisDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "versicolor    50\n",
       "setosa        50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDf['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irisDf2 = irisDf[irisDf.species != 'setosa']        # for binary classfication we made a new df by removing setosa class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "versicolor    50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDf2['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 50 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    100 non-null float64\n",
      "sepal_width     100 non-null float64\n",
      "petal_length    100 non-null float64\n",
      "petal_width     100 non-null float64\n",
      "species         100 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 4.7+ KB\n"
     ]
    }
   ],
   "source": [
    "irisDf2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50\n",
       "0    50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDf3 = irisDf2.replace('versicolor',0)        # replacing class 1 with value 0\n",
    "irisDf4 = irisDf3.replace('virginica',1)         # replacing class 2 with value 1\n",
    "#irisDf4.head()\n",
    "irisDf4['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "features = irisDf4.values[:,:4]    # till 3rd column means exclusive of 4th coln whch is target or label\n",
    "target = irisDf4.values[:,4]\n",
    "  \n",
    "#slicing data\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,\n",
    "                                                                            target, test_size = 0.33, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "# sigmoid or logistic function we are gonna use \n",
    "def sigmoid(scores):\n",
    "    return ( 1.0 / (1.0 + np.exp(-scores)))\n",
    "\n",
    "\n",
    "\n",
    "# finding log likelihood : we derived this L(w) where w is a vector of parameters we wnt to learn for which prob.\n",
    "# of classlabel is maximized\n",
    "\n",
    "# in following weights are parameters we want to learn for which we get the best or optimum answer\n",
    "# features and labels (target vals) , scores is our hypothese function before applying sigmoid function\n",
    "\n",
    "def log_likelihood(features, target, weights): \n",
    "    scores = np.dot(features, weights)      # scores is (wTranspose x) , target is yi or labels \n",
    "    ll = np.sum( target*scores - np.log(1 + np.exp(scores)) )      #look at this eqn we have derived as log likelihood\n",
    "    return ll\n",
    "\n",
    "# by taking derivative of loglikelihood eqn or ll we will get a gradient : which we ll use here\n",
    "\n",
    "def logistic_regression(features, target, num_steps, learning_rate, add_intercept = False):\n",
    "    if add_intercept:\n",
    "        intercept = np.ones((features.shape[0], 1))\n",
    "        features = np.hstack((intercept, features))\n",
    "        \n",
    "    weights = np.zeros(features.shape[1])     # intaliazing parameter values\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        scores = np.array(np.dot(features, weights),dtype=np.float32 )    # h(x) = wT.x\n",
    "        predictions = sigmoid(scores)      # our hypotheses function after applying sigmoid  : h(x) = sigmoid(wT.x) \n",
    "\n",
    "        # Update weights with gradient\n",
    "        #print(target)\n",
    "        #print(predictions)\n",
    "        output_error_signal = target - predictions      #  target means yi or actual labels , predictions means p(xi) or predicted prob.\n",
    "        gradient = np.dot(features.T, output_error_signal)    # this eqn we have derived : it is a derivative of ll : log likelihood\n",
    "        \n",
    "        weights += learning_rate * gradient       # forumula for G.D. Wnew = Wold + n * gradient : here + because we are maximizing\n",
    "        \n",
    "        # Print log-likelihood every so often\n",
    "        #if step % 10000 == 0:\n",
    "           # print(log_likelihood(features, target, weights))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#call to the function we have defined\n",
    "weights = logistic_regression(features, target,num_steps = 300000, learning_rate = 5e-5, add_intercept=True)\n",
    "\n",
    "# these are the parameter values we have learned for optimum ( maximum ) confidence for given class label : frm training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from scratch: 0.97\n"
     ]
    }
   ],
   "source": [
    "# accuracy of logistic regression with gradient descent \n",
    "\n",
    "data_with_intercept = np.hstack((np.ones((features.shape[0], 1)),features))\n",
    "final_scores = np.dot(data_with_intercept, weights)\n",
    "preds = np.round(sigmoid(final_scores))         # we are rounding final predicted prob. to neareset class label 0 or 1\n",
    "\n",
    "print(\"Accuracy from scratch: {0}\".format((preds == target).sum().astype(float) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
