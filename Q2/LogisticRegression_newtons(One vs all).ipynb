{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "irisDf = pd.read_csv('../datasets/Data_Q2/iris.csv')\n",
    "\n",
    "irisDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "versicolor    50\n",
       "setosa        50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDf['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica     37\n",
       "setosa        34\n",
       "versicolor    29\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "    \n",
    "# this will give dataframes as output of splitting \n",
    "traindf,testdf = train_test_split(irisDf,test_size=0.33)\n",
    "traindf['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irisSet = traindf.replace('versicolor',1).replace('virginica',1).replace('setosa',0)\n",
    "irisVe = traindf.replace('versicolor',0).replace('virginica',1).replace('setosa',1)\n",
    "irisVi = traindf.replace('versicolor',1).replace('virginica',0).replace('setosa',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    63\n",
       "0    37\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisVi['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 94 to 92\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    100 non-null float64\n",
      "sepal_width     100 non-null float64\n",
      "petal_length    100 non-null float64\n",
      "petal_width     100 non-null float64\n",
      "species         100 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 4.7 KB\n"
     ]
    }
   ],
   "source": [
    "irisSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#slicing data for setosa\n",
    "features_train_set = irisSet.values[:,:4]    # till 3rd column means exclusive of 4th coln whch is target or label\n",
    "target_train_set = irisSet.values[:,4]\n",
    "                                                                        \n",
    "#slicing data for virginica\n",
    "features_train_vi = irisVi.values[:,:4]    # till 3rd column means exclusive of 4th coln whch is target or label\n",
    "target_train_vi = irisVi.values[:,4]\n",
    "  \n",
    "#slicing data for versicolor\n",
    "\n",
    "features_train_ve = irisVe.values[:,:4]    # till 3rd column means exclusive of 4th coln whch is target or label\n",
    "target_train_ve = irisVe.values[:,4]\n",
    "\n",
    "#slicing test data which is common for all\n",
    "features_test = testdf.values[:,:4]\n",
    "target_test = testdf.values[:,4]\n",
    "#target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "# sigmoid or logistic function we are gonna use \n",
    "def sigmoid(scores):\n",
    "    return ( 1.0 / (1.0 + np.exp(-scores)))\n",
    "\n",
    "\n",
    "\n",
    "# finding log likelihood : we derived this L(w) where w is a vector of parameters we wnt to learn for which prob.\n",
    "# of classlabel is maximized\n",
    "\n",
    "# in following weights are parameters we want to learn for which we get the best or optimum answer\n",
    "# features and labels (target vals) , scores is our hypothese function before applying sigmoid function\n",
    "\n",
    "def log_likelihood(features, target, weights): \n",
    "    scores = np.dot(features, weights)      # scores is (wTranspose x) , target is yi or labels \n",
    "    ll = np.sum( target*scores - np.log(1 + np.exp(scores)) )      #look at this eqn we have derived as log likelihood\n",
    "    return ll\n",
    "\n",
    "# by taking derivative of loglikelihood eqn or ll we will get a gradient : which we ll use here\n",
    "\n",
    "def logistic_regression(features, target, num_steps, learning_rate, add_intercept = False):\n",
    "    if add_intercept:\n",
    "        intercept = np.ones((features.shape[0], 1))\n",
    "        features = np.hstack((intercept, features))\n",
    "        \n",
    "    weights = np.zeros(features.shape[1]).reshape(-1,1)     # intaliazing parameter values\n",
    "    target = target.reshape(-1,1)\n",
    "    m = features.shape[0]\n",
    "    for step in range(num_steps):\n",
    "        scores = np.array(np.dot(features, weights),dtype=np.float32 )    # h(x) = wT.x\n",
    "        predictions = sigmoid(scores)      # our hypotheses function after applying sigmoid  : h(x) = sigmoid(wT.x) \n",
    "\n",
    "        sigma = np.diag((predictions * (1 - predictions))[:,0])\n",
    "        #sigma = np.diag((sigma)[:,0])\n",
    "        #print(np.shape(sigma))\n",
    "        temp = np.dot(sigma, features)\n",
    "        hessian = np.dot(features.T, temp)\n",
    "        #print(hessian)\n",
    "        hessian_inv = np.linalg.inv(hessian)    \n",
    "\n",
    "        # Update weights with gradient\n",
    "        #print(target)\n",
    "        #print(predictions)\n",
    "        output_error_signal = target - predictions      #  target means yi or actual labels , predictions means p(xi) or predicted prob.\n",
    "        gradient = np.dot(features.T, output_error_signal) / m  # this eqn we have derived : it is a derivative of ll : log likelihood\n",
    "        #print(np.shape(target))\n",
    "        weights += (np.dot(hessian_inv, gradient))       # forumula for G.D. Wnew = Wold + n * gradient : here + because we are maximizing\n",
    "        \n",
    "        # Print log-likelihood every so often\n",
    "        #if step % 10000 == 0:\n",
    "           # print(log_likelihood(features, target, weights))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#call to the function we have defined\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "weights_set = logistic_regression(features_train_set, target_train_set ,num_steps = 1000, learning_rate = 5e-5, add_intercept=True)\n",
    "weights_vi = logistic_regression(features_train_vi, target_train_vi,num_steps = 1000, learning_rate = 5e-5, add_intercept=True)\n",
    "weights_ve = logistic_regression(features_train_ve, target_train_ve,num_steps = 1000, learning_rate = 5e-5, add_intercept=True)\n",
    "\n",
    "time = time.time() - t0\n",
    "\n",
    "# these are the parameter values we have learned for optimum ( maximum ) confidence for given class label : frm training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy of logistic regression with gradient descent \n",
    "\n",
    "data_with_intercept = np.hstack((np.ones((features_test.shape[0], 1)),features_test))\n",
    "final_scores_set = np.dot(data_with_intercept, weights_set)\n",
    "#print(final_scores_set)\n",
    "#preds_set = (sigmoid(final_scores_set))     # we are rounding final predicted prob. to neareset class label 0 or 1\n",
    "                                            # this is a sigmoid fun whch maps vals to 0 to 1\n",
    "\n",
    "# vi\n",
    "\n",
    "data_with_intercept = np.hstack((np.ones((features_test.shape[0], 1)),features_test))\n",
    "final_scores_vi = np.dot(data_with_intercept, weights_vi)\n",
    "#preds_vi = (sigmoid(final_scores_vi))         # we are rounding final predicted prob. to neareset class label 0 or 1\n",
    "\n",
    "# ve\n",
    "\n",
    "data_with_intercept = np.hstack((np.ones((features_test.shape[0], 1)),features_test))\n",
    "final_scores_ve = np.dot(data_with_intercept, weights_ve)\n",
    "#preds_ve = (sigmoid(final_scores_ve))         # we are rounding final predicted prob. to neareset class label 0 or 1\n",
    "\n",
    "\n",
    "#print(\"Accuracy from scratch: {0}\".format((preds == target).sum().astype(float) / len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final_scores_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_scores_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accruacy is :  96.0\n",
      "training time is :  0.256 seconds\n"
     ]
    }
   ],
   "source": [
    "final_pred = list()\n",
    "\n",
    "for i in range(0,len(final_scores_set)):\n",
    "    m = min(final_scores_set[i],final_scores_vi[i],final_scores_ve[i])\n",
    "    if(m == final_scores_set[i]):\n",
    "        final_pred.append(\"setosa\")\n",
    "    elif(m == final_scores_vi[i]):\n",
    "        final_pred.append(\"virginica\")\n",
    "    else:\n",
    "        final_pred.append(\"versicolor\")\n",
    "\n",
    "#print(final_pred)\n",
    "#print(target_test)\n",
    "#finding accuracy\n",
    "\n",
    "count =0        \n",
    "\n",
    "for i in range(0,len(final_scores_set)):\n",
    "    if(final_pred[i] == target_test[i]):\n",
    "        count += 1\n",
    "\n",
    "print(\"accruacy is : \",100 * (count/len(final_scores_set)))\n",
    "print(\"training time is : \", round( time, 3), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
